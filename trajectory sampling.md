# trajectory sampling
From [[model-based methods]]
$\physics$
## Definition
Instead of spending equal time updating each state-action pair we just sample them using our current model as environment and policy to explore it. So update happen according to [[on-policy distribution]].

## See also
- [[prioritized sweeping]] is another optimization. How are they related?