# value function
From [[reinforcement learning]]
$\physics$
Value function for a given state and [[policy]] is the expected total (sometimes discounted) [[reward signal]] that an agent can get from that state following that policy.

If the value function corresponding to one of the optimal policies is known, than greedily acting on it is also an optimal policy.