# model-based methods
From [[reinforcement learning]]
$\physics$
## Definition
Model-free techniques, such as [[temporal-difference learning]] or [[Monte Carlo methods]], known in general as learning, use real experience to update their values and policies. In contrast, model-based approaches, also knows as planning, use real experience to build a model of environment, and then use sampled from there experiences to update the values and policies.

## Examples
- [[dynamic programming methods]]
- [[Dyna-Q]], [[Dyna-Q+]]
- [[prioritized sweeping]], [[trajectory sampling]]
- [[decision-time planning]]